---
title: "Practica02"
author: "Brian Sandoval"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Practica 02:

1\. Descargar la página web de la URL indicada, y almacenarlo en un formato de R apto para ser tratado. El primer paso para realizar tareas de crawling y scraping es poder descargar los datos de la web. Para esto usaremos la capacidad de R y de sus librerías (httr y XML) para descargar webs y almacenarlas en variables que podamos convertir en un formato fácil de analizar (p.e. de HTML a XML).

```{r , echo=FALSE}
library(XML)
library(httr)
httr::GET("https://www.mediawiki.org/wiki/MediaWiki")
html <- GET("https://www.mediawiki.org/wiki/MediaWiki")
contenido <- content(html, as = "text")
parsedHtml <- htmlParse(contenido, asText = TRUE)
titulo <- xpathSApply(parsedHtml, "//title", xmlValue)
titulo
```

## 
